Hadoop dfs –mkdir –p /user/flume/tweets

flume-ng agent -n TwitterAgent -f <location of created/edited conf file>

hadoop dfs –ls /user/flume/tweets

hadoop dfs –cat /user/flume/tweets/<flumeData file name>



REGISTER '/home/edureka/Desktop/elephant-bird-hadoop-compat-4.1.jar;
REGISTER '/home/edureka/Desktop/elephant-bird-pig-4.1.jar';
REGISTER '/home/edureka/Desktop/json-simple-1.1.1.jar';


load_tweets = LOAD '/user/flume/tweets/' USING com.twitter.elephantbird.pig.load.JsonLoader('-nestedLoad') AS myMap;

extract_details = FOREACH load_tweets GENERATE myMap#'id' as id,myMap#'text' as text;

tokens = foreach extract_details generate id,text, FLATTEN(TOKENIZE(text)) As word

dictionary = load '/AFINN.txt' using PigStorage('\t') AS (word:chararray,rating:int);

word_rating = join tokens by word left outer, dictionary by word using 'replicated';

describe word_rating;

rating = foreach word_rating generate tokens::id as id,tokens::text as text, dictionary::rating as rate

word_group = group rating by (id,text);

avg_rate = foreach word_group generate group, AVG (rating.rate) as tweet_rating;

positive_tweets = filter avg_rate by tweet_rating>=0;